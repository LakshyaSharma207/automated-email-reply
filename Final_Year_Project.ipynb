{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk faiss-cpu llama-index-core==0.11.17 llama-index-vector-stores-faiss langchain-huggingface pinecone tran"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUwJ7l0aXeba",
        "outputId": "ef8fcced-84da-48cf-cc8f-68cf163bf414"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: llama-index-core==0.11.17 in /usr/local/lib/python3.10/dist-packages (0.11.17)\n",
            "Requirement already satisfied: llama-index-vector-stores-faiss in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.10/dist-packages (5.3.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.11.17) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (3.4)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.17) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.24.7)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.3.10)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.19.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.44.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.17) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.17) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.17) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.17) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.17) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.17) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.1.135)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core==0.11.17) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core==0.11.17) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.11.17) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.11.17) (3.10)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.11.17) (3.1.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.11.17) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.11.17) (3.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.11.17) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.11.17) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.11.17) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.11.17) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.17) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.11.17) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "df = pd.read_csv('/content/message_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY8otTiiXgjW",
        "outputId": "ffbcf49b-e12e-4fcd-ea4d-08f6a354cbdd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cleaning and Preprocessing**"
      ],
      "metadata": {
        "id": "oeeE97CvZLbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "  # Replace NaN values with an empty string\n",
        "  df['Subject'] = df['Subject'].fillna('')\n",
        "  df['Body'] = df['Body'].fillna('')\n",
        "\n",
        "  if isinstance(text, str):\n",
        "    # Remove links (URLs)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "     # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "  return text\n",
        "\n",
        "# Function to remove stop words\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])"
      ],
      "metadata": {
        "id": "izXY_IJnaEJf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w83KoDP2LHn4",
        "outputId": "6703a6bb-1600-4061-e88e-f031414d67ff"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 87 entries, 0 to 86\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Subject  87 non-null     object\n",
            " 1   Date     87 non-null     object\n",
            " 2   Body     76 non-null     object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean and preprocess subject and body columns\n",
        "df['cleaned_subject'] = df['Subject'].apply(clean_text).apply(remove_stopwords)\n",
        "df['cleaned_body'] = df['Body'].apply(clean_text).apply(remove_stopwords)\n",
        "\n",
        "# Combine cleaned subject and body for embedding\n",
        "combined_texts = [\n",
        "    f\"Subject: {row['cleaned_subject']} Body: {row['cleaned_body']}\"\n",
        "    for index, row in df.iterrows()\n",
        "]\n",
        "print(combined_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCRZiVqeYvyn",
        "outputId": "896fe270-b88c-41f8-e5ed-dc9138d10477"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: become nextjs pro Body: hey nextjs become wellknown ability build fast reliable full stack apps good reason developer experience top notch wide range features help easily build performancefirst apps able focus unique challenges app nextjs 15 react 19 coming soon important ever make sure full understanding nextjs works newer react features help build amazing experiences new course launched help build full stack invoice app using nextjs 15 learn intricacies nextjs 15 react 19 well also learn design responsive components using tailwind shadcnui add authentication social login organization support mfa clerk create manage databases relationships accross tables xata query wrangle data postgres server xata drizzle orm process payments invoices using stripe build custom email templates react react email send transaction emails resend deploy app vercel looooots important concepts inbetween best part course available free thanks course partners xata clerk making possible ready get started dig jump colby twitter youtube twitch discord spacejellydev colbyfayockcom unsubscribe product launches updates dont want receive updates future ebooks premium content stop emails update profile 113 cherry st 92768 seattle wa 981042205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-base-en-v1.5\"\n",
        "\n",
        "# Generate embeddings for combined texts\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "embeddings = hf_embeddings.embed_documents(combined_texts)\n",
        "\n",
        "dimention = len(embeddings[0])\n",
        "print(dimention)  # Dimensionality of embedding space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK40FmTvafbS",
        "outputId": "61850dc6-8a8e-4738-d858-1c6484ac5626"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-pinecone langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxmXT2c1T7DQ",
        "outputId": "302b84cf-1b50-4801-847e-6dfe2f700be2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-pinecone in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: aiohttp<3.10,>=3.9.5 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (3.9.5)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (0.3.10)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (1.26.4)\n",
            "Requirement already satisfied: pinecone-client<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (5.0.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Collecting langchain<0.4.0,>=0.3.3 (from langchain_community)\n",
            "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.135)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.3->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.3->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (4.66.5)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2.2.3)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-pinecone) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain-pinecone) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.3-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, pydantic-settings, langchain-text-splitters, langchain, langchain_community\n",
            "Successfully installed langchain-0.3.3 langchain-text-splitters-0.3.0 langchain_community-0.3.2 pydantic-settings-2.5.2 python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['PINECONE_API_KEY'] = 'pinecone_api_key'\n",
        "os.environ['PINECONE_API_ENV'] = '<YOUR_PINECONE_ENVIRONMENT>'"
      ],
      "metadata": {
        "id": "EOdMHaePK3SG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone as PineconeClient, ServerlessSpec\n",
        "\n",
        "pc = PineconeClient(api_key=\"88c2edde-2d71-480a-aeff-62c7061bd7f2\")\n",
        "\n",
        "index_name = \"example-index\"\n",
        "pinecone_index = pc.Index(index_name)\n",
        "\n",
        "# run only once\n",
        "\n",
        "# dimentions = len(embeddings[0])\n",
        "# pc.create_index(\n",
        "#   name=\"example-index\",\n",
        "#   dimension=dimentions,\n",
        "#   metric=\"cosine\",\n",
        "#   spec=ServerlessSpec(\n",
        "#     cloud=\"aws\",\n",
        "#     region=\"us-east-1\"\n",
        "#   )\n",
        "# )"
      ],
      "metadata": {
        "id": "QVV57xJ9WDE4"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "texts = [\"Tonight, I call on the Senate to: Pass the Freedom to Vote Act.\", \"ne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\", \"One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\"]\n",
        "\n",
        "vectorstore_from_texts = PineconeVectorStore.from_texts(\n",
        "    texts,\n",
        "    index_name=index_name,\n",
        "    embedding=hf_embeddings\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Pinecone VectorStoreIndex successfully created using Hugging Face embeddings!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yNppfrIgMG5",
        "outputId": "2c127849-3c40-46f6-c684-12d22dc07857"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone VectorStoreIndex successfully created using Hugging Face embeddings!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.add_texts(combined_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W87VtgzZauu",
        "outputId": "9c49ef49-64b0-4b83-962d-5c74fa4dbda3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['04a23c8b-edc5-4f04-984b-96e24189f2f4',\n",
              " 'fae1e255-f01d-40c9-8c92-dd3cf0db66bb',\n",
              " '4492a873-22fd-4dd1-9a2c-f7fdff3f879c',\n",
              " 'debe3bae-29e6-4768-82d1-e7575c533a82',\n",
              " '621d0828-6ec6-450b-afe4-fdd7cb425536',\n",
              " 'feac9537-b04a-46a9-a3ad-700e343db69b',\n",
              " '3c2d3c81-17a4-40a1-9a44-8f0ca47df53a',\n",
              " '0e559a67-ecf8-4136-8fb5-1ba2c92de2ec',\n",
              " '880fec04-b0c0-4da9-8489-1a2d4eb2b119',\n",
              " '99bf92c6-0b20-45d1-9f3a-88a6f1bd1bbe',\n",
              " '45fc6c61-cbe9-4383-9881-0706e1a4f62b',\n",
              " '5e4f50b0-2799-480d-9d23-4ee14439db08',\n",
              " 'a6b71dac-3215-4eb2-b5e8-cf29d8309e91',\n",
              " '3477ad7f-4891-4322-aa34-979ed9802b44',\n",
              " 'baa0873b-f6c5-4714-8552-4fdad04ea644',\n",
              " 'f9545cb6-6821-4925-9376-46a975c4a0c4',\n",
              " 'a13b491c-a27b-4a05-bd72-6ac0a4f99fa0',\n",
              " '62bbb70f-ff79-43e7-843d-6e04e316ca02',\n",
              " '7714d6de-0720-4b1a-b3b6-ca1575c0dd20',\n",
              " '55242ecc-0bd5-4f80-b20a-add29a124528',\n",
              " '08e9891f-b55a-405c-9e8c-5c5962c19939',\n",
              " 'ec1d2144-29e8-4d7a-89bc-7c2f071973b7',\n",
              " '19511adc-6c2d-4e42-b44f-61d761f85304',\n",
              " '9006bb7e-e30d-4f42-9378-506b21706774',\n",
              " 'acd559e1-bde9-4b26-9d51-88d87f683793',\n",
              " '1ba46de4-658a-49c8-8535-b45fe9358e01',\n",
              " '0ba9167e-11c6-4932-b198-bc5a2a3fbfea',\n",
              " 'd467ebab-2043-4621-8e1b-5325b6bc3678',\n",
              " 'b34fbf94-4cd2-4ba3-8719-fa7030ce2501',\n",
              " '1e5044e1-f732-4b3e-8a40-04edf0da195e',\n",
              " '239f3ccb-25bb-4337-8ba0-2e17d5f67e16',\n",
              " '574f45eb-2aac-4685-a2d0-959133fe750d',\n",
              " 'fbdc2214-a48b-496a-8d50-b3038c7d6ad4',\n",
              " 'e77e44cd-f031-4c7d-8239-e46bb556e865',\n",
              " '9f5cc90b-3bdc-4468-8c09-29bb0f3631dd',\n",
              " '4ae123af-e19b-4209-af4e-0f5decf505a8',\n",
              " '9fc6a0ed-83ae-4363-a792-25577e19c64c',\n",
              " '13cfff83-4a2f-4f30-a21c-7dec8f443629',\n",
              " '17206924-3dcc-4258-bf89-2f115185fd30',\n",
              " 'b76c60d9-945e-4bb7-9813-6343960148d7',\n",
              " '6eb779ed-b679-468c-9149-908df28a81de',\n",
              " 'f675ca62-e84a-41da-98e3-1340a2142ee6',\n",
              " '7cefdc92-38e8-41cd-b1ab-b3e47f6f6f15',\n",
              " '1a3c6556-6154-4f51-9b4a-86aba90230d6',\n",
              " 'a6eaf470-7a1d-4c03-8811-9024c33bebbd',\n",
              " '1a11cdf1-d878-4cd2-aaa2-0db38255d440',\n",
              " 'd2f9b8fa-f9f8-4bae-8fde-a25708aa9eba',\n",
              " 'd66da6ca-1a02-4df2-b5aa-ebf78a56785f',\n",
              " '94189613-db1b-4491-a9ca-51b72883ea4d',\n",
              " '35d7af0b-045e-4cc7-97fb-7d2be8ba64b0',\n",
              " 'adc28b28-d535-4e5d-891c-ce8d60f0f565',\n",
              " '054cd684-dc69-48ad-8e8e-200f37e4e677',\n",
              " '03b421c9-0036-4fb2-b416-95afdf452c5d',\n",
              " '6405132e-5da2-4040-90f7-c2ab56a99e83',\n",
              " 'a8f92a82-7683-4791-b9ee-181bcdaf2681',\n",
              " 'e41f8a4f-0978-4f04-af75-52c36cf98ab9',\n",
              " '9f845354-5ec0-4ab7-ad02-f509a7d7804f',\n",
              " '73394473-9460-4697-b005-dc54d01a94fc',\n",
              " '20dbd570-f27e-4a5e-933c-6c7388939d5e',\n",
              " '7f803c2c-3454-4285-8677-b72aa1a919c5',\n",
              " '11bb84de-f4ed-4634-9aa4-a7b602b187db',\n",
              " '71cc5a92-b43e-40d1-9c96-f494a3c08a95',\n",
              " '1323728b-4474-4abe-b2c8-7a419df5a1ef',\n",
              " '2f38abae-5efa-4ca2-82a8-eb91477958e0',\n",
              " '1302303b-cfc9-40b7-bc70-879007095eb7',\n",
              " '8a2acff3-2e5b-4432-b3b5-d4b9873ce6f7',\n",
              " '2a13eb6a-1ed4-4f1c-a826-42d83a4bf9d6',\n",
              " 'f5420940-79c0-4279-af26-9f26ff8fa8d8',\n",
              " '74a1cccb-b477-4e55-8f70-744c3452b46e',\n",
              " 'f6efdb4a-127a-4113-8401-5f6fc116e5ab',\n",
              " '79daba96-c5be-4d0b-ad94-cb268a0aa9bd',\n",
              " '1f8f0a1f-5d09-4e77-9ebe-d6700ecfbf2a',\n",
              " '84fbbeea-04de-411f-82b2-a7374bfbde89',\n",
              " '691c3ecb-f9a1-40e6-aaef-ed6ca555cd10',\n",
              " '7d3c9aa2-e064-42bf-9123-032002edfec4',\n",
              " 'c0167337-0b7e-4339-9489-5473452f3a76',\n",
              " '450cb2ff-2674-4740-8689-cc3399031bbf',\n",
              " 'c9977023-ad3a-47df-859b-ff3c54dd0a9a',\n",
              " '1403eca6-fce0-4e15-811f-f316b5230604',\n",
              " 'd9eef5b2-4abc-4994-bffd-4e18ab3720bd',\n",
              " '0efe2e1a-5fb8-4507-8bb7-7d1af294fa12',\n",
              " 'cb7adab3-54b5-4196-97e3-1f073090adf5',\n",
              " 'cae3e24c-b06a-4895-938f-ff444fe96dc5',\n",
              " 'bff52b32-9323-498c-84b8-2402f429dd33',\n",
              " 'ad47d2c8-bfcc-4f2a-aab9-530e4258d2ed',\n",
              " '51d59810-4fcb-4758-b2d1-1c5e7e3a8038',\n",
              " '039ba884-d2e5-4b5c-8180-51c1071608e9']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is dropbox basic basic account size?\"\n",
        "vectorstore.similarity_search(query, k=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBEARM5WYzaj",
        "outputId": "a035835a-77c8-4363-eb45-acc159b0ea13"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2f38abae-5efa-4ca2-82a8-eb91477958e0', metadata={}, page_content='Subject: sharings easy dropbox Body: everyone gets 500 mb free space sharings easy dropbox invite friends dropbox get 16 gb bonus storage referring friends get bonus storage well complete signup process need dropbox need space everybody wins send invite ____________________________________________________ dropbox inc po box 77767 san francisco ca 94107 view privacy policy2 unsubscribe3 1 2 3'),\n",
              " Document(id='f6efdb4a-127a-4113-8401-5f6fc116e5ab', metadata={}, page_content='Subject: want Body: learn make life easier dropbox else dropbox probably signed dropbox store share couple files get started youll find helpful cloud storage learn plus family help get dropbox learn dropbox plus level file storage sharing limits builtin tools help organize digital life save share photos videos sensitive documents 2000 gb secure cloud storage access everything need 247 synced across devices dropbox passwords easily sign websites apps devices check plus dropbox family keep member household organized connectedeveryone gets individual accounts plus communal space easy sharing bring whole family board 6 users keep birth certificates medical info safe 2000 gb shared storage never miss photo update family room folder easy sharing check family dropbox professional specially designed help freelancers small business owners stay organized save time 3000 gb storage sync across devices customizable branding watermarks security check professional sounds like help make life little easier take minute compare different offerings compare dropbox products ____________________________________________________ dropbox inc po box 77767 san francisco ca 94107 view privacy policy5 unsubscribe6 1 2 3 4 5 6')]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", trust_remote_code=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9Xgf6VCEc2CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_email_reply(query):\n",
        "    # Perform similarity search in the vector store\n",
        "    results = vectorstore.similarity_search(query, k=2)\n",
        "\n",
        "    # Extract relevant content from the search results\n",
        "    relevant_texts = [result.page_content for result in results]\n",
        "\n",
        "    # Construct a prompt for the LLM\n",
        "    prompt = f\"Based on the following information, reply to this email:\\n\\n{query}\\n\\nRelevant information:\\n\" + \"\\n\".join(relevant_texts)\n",
        "\n",
        "    # Tokenize input and generate response\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=150)  # Adjust max_length as needed\n",
        "\n",
        "    # Decode and return the reply from the LLM's output\n",
        "    reply = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return reply\n",
        "\n",
        "# Example usage\n",
        "email_query = \"What is Dropbox's basic account size?\"\n",
        "reply = generate_email_reply(email_query)\n",
        "print(reply)"
      ],
      "metadata": {
        "id": "dkFEyPvodAuP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}