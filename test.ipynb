{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.PersistentClient(path=\"vectordb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"email_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\xa0', '', text)\n",
    "    text = re.sub(r'\\r', '', text)\n",
    "    text = re.sub(r'\\u200c', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_text(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from server import service\n",
    "\n",
    "def fetch_emails(service, user_id='me', max_results=100):\n",
    "    try:\n",
    "        # Fetch the list of messages\n",
    "        results = service.users().messages().list(userId=user_id, maxResults=max_results).execute()\n",
    "        messages = results.get('messages', [])\n",
    "        \n",
    "        email_data = []\n",
    "        for message in messages:\n",
    "            msg = service.users().messages().get(userId=user_id, id=message['id']).execute()\n",
    "            email_data.append(msg)\n",
    "        \n",
    "        return email_data\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def add_emails_to_collection(collection, emails):\n",
    "    for email in emails:\n",
    "        # For example, extract subject, sender, etc.\n",
    "        subject = next(header['value'] for header in email['payload']['headers'] if header['name'] == 'Subject')\n",
    "        sender = next(header['value'] for header in email['payload']['headers'] if header['name'] == 'From')\n",
    "        snippet = email.get('snippet', '')\n",
    "        mssg_id = email['id']\n",
    "\n",
    "        # Clean the extracted text\n",
    "        clean_subject = clean_text(subject)\n",
    "        clean_sender = clean_text(sender)\n",
    "        clean_snippet = clean_text(snippet)\n",
    "\n",
    "        # Extract image data if available\n",
    "        image_data = []\n",
    "        if 'parts' in email['payload']:\n",
    "            for part in email['payload']['parts']:\n",
    "                if part['filename'] and 'image' in part['mimeType']:\n",
    "                    # Decode the image data\n",
    "                    img_data = base64.urlsafe_b64decode(part['body']['data'])\n",
    "                    image_data.append(img_data)\n",
    "\n",
    "        # Split the snippet into chunks\n",
    "        snippet_chunks = split_text(clean_snippet)\n",
    "\n",
    "        # Add each chunk to the collection\n",
    "        for i, chunk in enumerate(snippet_chunks):\n",
    "            chunk_id = f\"{mssg_id}_{i}\"\n",
    "            collection.add(\n",
    "                ids=[chunk_id],\n",
    "                metadatas=[{\n",
    "                    'subject': clean_subject,\n",
    "                    'sender': clean_sender,\n",
    "                    'chunk_index': i\n",
    "                }],\n",
    "                documents=[chunk]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "emails = fetch_emails(service)\n",
    "print(len(emails))\n",
    "add_emails_to_collection(collection, emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what are the new dropbox features', 'hello dropbox has recently introduced some exciting new features to help you better manage your digital content here are a few key updates 1 automated folders create folders that automatically', 'new features quality enhancements and much more', 'get creative cloud all apps one plan endless possibilities bring any idea to life with the creative cloud all apps plan get photoshop illustrator adobe express and the latest generative ai', 'create quickly and easily with templates from adobe express kick off the holiday spirit with a spectacular party invite making holidaythemed party invites is easy with adobe express browse from']]\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"dropbox features\"],\n",
    "    n_results=5\n",
    ")\n",
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collection Exists!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_collection = chroma_client.get_collection(name=\"email_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what are the new dropbox features', 'hello dropbox has recently introduced some exciting new features to help you better manage your digital content here are a few key updates 1 automated folders create folders that automatically', 'new features quality enhancements and much more', 'get creative cloud all apps one plan endless possibilities bring any idea to life with the creative cloud all apps plan get photoshop illustrator adobe express and the latest generative ai', 'create quickly and easily with templates from adobe express kick off the holiday spirit with a spectacular party invite making holidaythemed party invites is easy with adobe express browse from']]\n"
     ]
    }
   ],
   "source": [
    "results = old_collection.query(\n",
    "    query_texts=[\"dropbox features\"],\n",
    "    n_results=5\n",
    ")\n",
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Generate Reply**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "sec_key = config[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_huggingface'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEndpoint\n\u001b[1;32m      3\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFaceEndpoint(repo_id\u001b[38;5;241m=\u001b[39mrepo_id, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, token\u001b[38;5;241m=\u001b[39msec_key)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_huggingface'"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=128, temperature=0.7, token=sec_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
