{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.PersistentClient(path=\"vectordb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"email_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\xa0', '', text)\n",
    "    text = re.sub(r'\\u200c', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_text(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from server import service\n",
    "\n",
    "def fetch_emails(service, user_id='me', max_results=100):\n",
    "    try:\n",
    "        # Fetch the list of messages\n",
    "        results = service.users().messages().list(userId=user_id, maxResults=max_results).execute()\n",
    "        messages = results.get('messages', [])\n",
    "        \n",
    "        email_data = []\n",
    "        for message in messages:\n",
    "            msg = service.users().messages().get(userId=user_id, id=message['id']).execute()\n",
    "            email_data.append(msg)\n",
    "        \n",
    "        return email_data\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def add_emails_to_collection(collection, emails):\n",
    "    for email in emails:\n",
    "        # For example, extract subject, sender, etc.\n",
    "        subject = next(header['value'] for header in email['payload']['headers'] if header['name'] == 'Subject')\n",
    "        sender = next(header['value'] for header in email['payload']['headers'] if header['name'] == 'From')\n",
    "        snippet = email.get('snippet', '')\n",
    "        mssg_id = email['id']\n",
    "\n",
    "        # Clean the extracted text\n",
    "        clean_subject = clean_text(subject)\n",
    "        clean_sender = clean_text(sender)\n",
    "        clean_snippet = clean_text(snippet)\n",
    "\n",
    "        # Extract image data if available\n",
    "        image_data = []\n",
    "        if 'parts' in email['payload']:\n",
    "            for part in email['payload']['parts']:\n",
    "                if part['filename'] and 'image' in part['mimeType']:\n",
    "                    # Decode the image data\n",
    "                    img_data = base64.urlsafe_b64decode(part['body']['data'])\n",
    "                    image_data.append(img_data)\n",
    "\n",
    "        # Split the snippet into chunks\n",
    "        snippet_chunks = split_text(clean_snippet)\n",
    "\n",
    "        # Add each chunk to the collection\n",
    "        for i, chunk in enumerate(snippet_chunks):\n",
    "            chunk_id = f\"{mssg_id}_{i}\"\n",
    "            collection.add(\n",
    "                ids=[chunk_id],\n",
    "                metadatas=[{\n",
    "                    'subject': clean_subject,\n",
    "                    'sender': clean_sender,\n",
    "                    'chunk_index': i\n",
    "                }],\n",
    "                documents=[chunk]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "emails = fetch_emails(service)\n",
    "print(len(emails))\n",
    "add_emails_to_collection(collection, emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what are the new dropbox features', 'hello dropbox has recently introduced some exciting new features to help you better manage your digital content here are a few key updates 1 automated folders create folders that automatically', 'new features quality enhancements and much more', 'get creative cloud all apps one plan endless possibilities bring any idea to life with the creative cloud all apps plan get photoshop illustrator adobe express and the latest generative ai', 'create quickly and easily with templates from adobe express kick off the holiday spirit with a spectacular party invite making holidaythemed party invites is easy with adobe express browse from']]\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"dropbox features\"],\n",
    "    n_results=4\n",
    ")\n",
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collection Exists!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_collection = chroma_client.get_collection(name=\"email_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what are the new dropbox features', 'hello dropbox has recently introduced some exciting new features to help you better manage your digital content here are a few key updates 1 automated folders create folders that automatically', 'new features quality enhancements and much more', 'get creative cloud all apps one plan endless possibilities bring any idea to life with the creative cloud all apps plan get photoshop illustrator adobe express and the latest generative ai', 'create quickly and easily with templates from adobe express kick off the holiday spirit with a spectacular party invite making holidaythemed party invites is easy with adobe express browse from']]\n"
     ]
    }
   ],
   "source": [
    "results = old_collection.query(\n",
    "    query_texts=[\"dropbox features\"],\n",
    "    n_results=5\n",
    ")\n",
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Generate Reply**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "sec_key = config[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=128, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_email = {\n",
    "    \"Subject\": \"test mail\",\n",
    "    \"From\": \"Proxylol Account <proxylola193@gmail.com>\",\n",
    "    \"To\": \"\\\"shogunmasters54@gmail.com\\\" <shogunmasters54@gmail.com>\",\n",
    "    \"Body\": \"Hello how are you? I was thinking to complete the project this sunday. Confirm if you are available.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draftEmail(email):\n",
    "    # Perform a query search with the email body\n",
    "    query_results = old_collection.query(\n",
    "        query_texts=[email[\"Body\"]],\n",
    "        n_results=4\n",
    "    )\n",
    "    context_chromadb = query_results[\"documents\"]\n",
    "    print(context_chromadb)\n",
    "    \n",
    "    # reply for the mail\n",
    "    reply_subject = f\"Re: {email['Subject']}\"\n",
    "\n",
    "    # Prompt for the email body\n",
    "    body_prompt = f\"Email Body:\\n{email['Body']}, Email Subject:\\n{email['Subject']}\\n\\nRelevant Context:\\n{context_chromadb}\\n\\nDraft a reply to this email. Include only the body of the email:\"\n",
    "    reply_draft = llm.invoke(body_prompt)\n",
    "\n",
    "    # Combine subject and body drafts into the final email format\n",
    "    final_email = {\n",
    "        \"Subject\": reply_subject.strip(),\n",
    "        \"Body\": reply_draft.strip(),\n",
    "        \"From\": email[\"To\"],\n",
    "        \"To\": email[\"From\"]\n",
    "    }\n",
    "\n",
    "    return final_email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['don39t miss out on your creative boost the creativity conference 1516 oct free online event adobe max two weeks until max  don39t miss out mark your calendars only two weeks to go until the', 'steam 1 game you39ve wished for is on sale the witness 75  849  212 week long deal offer ends 23 sep 1000pm ist you wake up alone on a strange island full of puzzles that will challenge and', 'create stunning designs in minutes for free dial up the diwali spirit with stunning designs this diwali illuminate your creativity create dazzling greetings social contents flyers and more with', 'stock up on everything you need to bring seasonal projects to life get in the spirit early it39s never too early to get a head start on your holiday projects with cozy festive content from adobe']]\n",
      "{'Subject': 'Re: test mail', 'Body': \"Hi there,\\n\\nYes, I am available this Sunday to complete the project. Let's make it happen!\\n\\nBest,\\n[Your Name]\", 'From': '\"shogunmasters54@gmail.com\" <shogunmasters54@gmail.com>', 'To': 'Proxylol Account <proxylola193@gmail.com>'}\n"
     ]
    }
   ],
   "source": [
    "print(draftEmail(new_email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-To-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "def generate_image_captions(img_path):\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "    raw_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    # conditional image captioning\n",
    "    text = \"an image of\"\n",
    "    inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "\n",
    "    out = model.generate(**inputs)\n",
    "    print(\"Conditional caption:\", processor.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "    # unconditional image captioning\n",
    "    inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "\n",
    "    out = model.generate(**inputs)\n",
    "    print(\"Unconditional caption:\", processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: Error 400: {\"error\":[\"Error in `inputs`: Invalid image: b'--7672d76e43e58c520b..'\"]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Hugging Face API URL and your personal token\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "headers = {\"Authorization\": f\"Bearer YOUR_API_TOKEN_HERE\"}\n",
    "\n",
    "def generate_image_caption_endpoint(img_path):\n",
    "    \"\"\"\n",
    "    Sends an image to the Hugging Face endpoint to generate captions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image in binary mode\n",
    "        with open(img_path, \"rb\") as img_file:\n",
    "            response = requests.post(API_URL, headers=headers, files={\"image\": img_file})\n",
    "\n",
    "        # Handle the response\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"generated_text\"]  # Extract the caption\n",
    "        else:\n",
    "            return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: The image file was not found. Please check the file path.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Example Usage\n",
    "image_path = \"path/to/your/image.jpg\"  # Replace with your image file path\n",
    "caption = generate_image_caption_endpoint(image_path)\n",
    "print(\"Generated Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_image_captions(new_emails['attachments'])\n",
    "generate_image_captions('image_attachments/kutta.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio-To-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Who are you talking to right now? Do you know how much I make a year? I mean, even if I told you, you wouldn't believe it. Do you know what would happen if I suddenly decided to stop going into work? A business big enough that it could be listed on the NASDAQ goes belly up. Disappears. It ceases to exist without me. No, you clearly don't know who you're talking to, so let me clue you in. I am not in danger. I am the danger. A guy opens his door and gets shot and you think that of me? No. I am the one who knocks.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set your Hugging Face API token and model endpoint\n",
    "MODEL_ID = 'openai/whisper-large-v3-turbo'\n",
    "URL = f'https://api-inference.huggingface.co/models/openai/whisper-large-v3-turbo'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {sec_key}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Load your audio file\n",
    "audio_file_path = 'audio_attachments/who-are-you-talking-to.mp3'\n",
    "with open(audio_file_path, 'rb') as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "# Send a POST request to the model\n",
    "response = requests.post(URL, headers=headers, files={'file': audio_data})\n",
    "\n",
    "# Check for successful response\n",
    "if response.status_code == 200:\n",
    "    transcription = response.json()\n",
    "    print(transcription['text'])\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
